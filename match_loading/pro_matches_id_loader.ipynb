{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import multiprocessing\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import DuplicateKeyError\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client['dota']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_matches_id_coll = db.pro_matches_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_working_proxy():\n",
    "    user_agent = {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; Win64; x64;en; rv:5.0) \\\n",
    "                  Gecko/20110619 Firefox/5.0'}\n",
    "    proxy_list_site = 'https://free-proxy-list.net/'\n",
    "    pm = urllib3.PoolManager(1, \n",
    "                             headers=user_agent, \n",
    "                             cert_reqs='CERT_REQUIRED')\n",
    "    prx_req = pm.request('GET', proxy_list_site)\n",
    "    prx_soup = BeautifulSoup(prx_req.data, 'html.parser')\n",
    "    proxies_list = []\n",
    "    for tr in prx_soup.find_all('tr'):\n",
    "        tmp = []\n",
    "        for td in tr.find_all('td')[:2]:\n",
    "            tmp.append(td.text)\n",
    "        if len(tmp) < 2:\n",
    "            continue\n",
    "        proxies_list.append([str(tmp[0]) + ':' + tmp[1]])\n",
    "    \n",
    "    proxies_list = proxies_list[:20]\n",
    "    np.random.shuffle(proxies_list)\n",
    "    for i, prx in enumerate(proxies_list):\n",
    "        try:\n",
    "            print('Getting working proxy...')\n",
    "            cur_prx_address = 'https://' + str(prx[0]) + '/'\n",
    "            prx_http = urllib3.ProxyManager(cur_prx_address,\n",
    "                                            maxsize=1, \n",
    "                                            headers=user_agent, \n",
    "                                            cert_reqs='CERT_REQUIRED')\n",
    "            r = prx_http.request('GET', 'https://stackoverflow.com/', timeout=0.7)\n",
    "            if r.status == 200:\n",
    "                print('Proxy found.')\n",
    "                return cur_prx_address\n",
    "            time.sleep(0.1)\n",
    "        except Exception as err:\n",
    "            # print(err)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_pro_matches_id(prx_address, start_id=9994966018):\n",
    "    url = 'https://api.opendota.com/api/proMatches?less_than_match_id='\n",
    "    user_agent = {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1; Win64; x64;en; rv:5.0) \\\n",
    "                  Gecko/20110619 Firefox/5.0'}\n",
    "    cur_url = url + str(start_id)\n",
    "    prx_m = urllib3.ProxyManager(prx_address, headers=user_agent, cert_reqs='CERT_REQUIRED')\n",
    "    r = prx_m.request('GET', cur_url, timeout=1)\n",
    "    matches = json.loads(r.data)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_id = 9994966018\n",
    "cur_prx = get_working_proxy()\n",
    "for i in range(1000):\n",
    "    total_matches = pro_matches_id_coll.count()\n",
    "    print(i, total_matches, last_id) if i % 10 == 0 else None\n",
    "    try:\n",
    "        cur_matches = api_pro_matches_id(cur_prx, start_id=last_id)\n",
    "        ids = [x['match_id'] for x in cur_matches]\n",
    "        if hasattr(cur_matches, 'error') and cur_matches['error'] == 'rate limit exceeded':\n",
    "            cur_prx = get_working_proxy()\n",
    "            continue\n",
    "        last_id = np.min(ids)\n",
    "        pro_matches_id_coll.insert(cur_matches)\n",
    "        total_matches = pro_matches_id_coll.count()\n",
    "    except DuplicateKeyError as de:\n",
    "        continue\n",
    "    except Exception as err:\n",
    "        # raise\n",
    "        print(err)\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
